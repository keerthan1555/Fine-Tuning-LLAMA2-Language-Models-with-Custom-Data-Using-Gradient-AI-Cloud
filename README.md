**Overview:** Explored fine-tuning Llama2 models with custom data on Gradient AI platform using Python SDK.

**Technologies:** Utilized Gradient AI platform with Python SDK, workspace ID, and access tokens, leveraging base models like Bloom560, Llama27b, and NoShermas2.

**Outcome:** Achieved efficient fine-tuning process, including model adapter creation and sample data fine-tuning, resulting in improved response accuracy on Gradient Cloud platform.


Explore Gradient's platform for fine-tuning LLM models with custom data.
Obtain necessary credentials like Workspace ID and access tokens for workspace creation.
Follow provided documentation and minimal code snippets for easy model fine-tuning.
Install Gradient AI and configure workspace ID for the fine-tuning process.
Initialize Gradient environment, retrieve base models, and create adapters for custom data fine-tuning.
Utilize Python SDK to create custom data and perform fine-tuning using the "do fine tune" method.
Increment epochs for accuracy improvement and execute sample queries to evaluate generated outputs.
Test and fine-tune LLM models efficiently within the Gradient Cloud platform.
Keep the option to delete the model post fine-tuning or retain it for future applications.


https://github.com/keerthan1555/Fine-Tuning-LLAMA2-Language-Models-with-Custom-Data-Using-Gradient-AI-Cloud/blob/main/image%201.png

https://github.com/keerthan1555/Fine-Tuning-LLAMA2-Language-Models-with-Custom-Data-Using-Gradient-AI-Cloud/blob/main/image%202.png

https://github.com/keerthan1555/Fine-Tuning-LLAMA2-Language-Models-with-Custom-Data-Using-Gradient-AI-Cloud/blob/main/image%203.png
